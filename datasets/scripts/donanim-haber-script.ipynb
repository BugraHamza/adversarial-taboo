{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce543587-ae01-4333-acfc-1f5b58e46e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c606c-f0d6-4619-83df-fd8badc4f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediawiki_dump.dumps import WikipediaDump\n",
    "from mediawiki_dump.reader import DumpReaderArticles\n",
    "from mediawiki_dump.tokenizer import clean, tokenize\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def wiki2csv(lang):\n",
    "    dump = WikipediaDump(lang)\n",
    "    pages = DumpReaderArticles().read(dump)\n",
    "    \n",
    "    with open(f\"{lang}_wiki.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'title', 'content'])\n",
    "        \n",
    "        for page in tqdm(pages):\n",
    "            writer.writerow([page.page_id, page.title, clean(page.content)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b9554f-5133-4996-9288-e244fd15c5ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turkish Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7169cd-8d83-40b8-9326-95ce306746e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki2csv(\"tr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6e6cb-82a9-4850-895d-252ae2d48f04",
   "metadata": {},
   "source": [
    "### PoS-Tagged Turkish Wiki\n",
    "\n",
    "Using Wikipedia articles in csv file, a new pos-tagged wiki dataset is generated.\n",
    "\n",
    "PoS Taggers:\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94818bb6-a9ec-4c83-8161-e0fd52129bd4",
   "metadata": {},
   "source": [
    "# Forum Donanim Haber Dataset\n",
    "\n",
    "521 url den 158 row çıktı.\n",
    "536 url den 178 row çıktı.\n",
    "1000 url den 232 row çıktı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d1ef5-29d0-4e4e-8683-8a80e5f23fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class DHCrawler:\n",
    "    def __init__(self, base_site):\n",
    "        self.data_dict = {}\n",
    "        \n",
    "        self.base_site = base_site\n",
    "        self.n_row = 0\n",
    "        \n",
    "        self.visited_crawl = []\n",
    "        self.unvisited_crawl = [base_site]\n",
    "        \n",
    "        self.link_list = []\n",
    "                \n",
    "    def __call__(self, filename):\n",
    "        with open(f\"{filename}.csv\", \"a\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['id', 'url', 'post', 'response'])\n",
    "            \n",
    "        while self.n_row < 10000:\n",
    "            self._crawl_pages()\n",
    "            self.crawl(filename=filename)\n",
    "    \n",
    "    def _crawl_pages(self):\n",
    "        while len(self.link_list) < 1000:\n",
    "            pop_index = random.randint(0, len(self.unvisited_crawl)-1)\n",
    "            site = self.unvisited_crawl.pop(pop_index)\n",
    "\n",
    "            self._get_pages(site)\n",
    "            self.visited_crawl.append(site)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            print(f\"Unvisited: {len(self.unvisited_crawl)} Visited: {len(self.visited_crawl)} Forum : {len(self.link_list)}\")\n",
    "            \n",
    "    def _get_pages(self, site):\n",
    "        req = requests.get(site)\n",
    "        if req.status_code == 200:\n",
    "            content = req.content\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            \n",
    "            queue = soup.find_all(href=True)\n",
    "            \n",
    "            for el in queue:\n",
    "                link = el['href']\n",
    "                \n",
    "                try:\n",
    "                    if link[0] == '/':\n",
    "                        link = self.base_site + link\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                if self.base_site in link and link not in self.unvisited_crawl and link not in self.visited_crawl:\n",
    "                    search_obj = re.search(r\"https://forum.donanimhaber.com/\\S*--f\", link)\n",
    "                \n",
    "                    if search_obj:\n",
    "                        self.unvisited_crawl.insert(0, link)\n",
    "                    else:\n",
    "                        self.unvisited_crawl.append(link)\n",
    "                        \n",
    "                    search_obj = re.search(r\"https://forum.donanimhaber.com/\\S*--\\d{9}\", link)\n",
    "                    if search_obj and search_obj.span()[1] == len(link):\n",
    "                        self.link_list.append(link)\n",
    "\n",
    "    def crawl(self, filename):\n",
    "        def crawl_single_page(url):\n",
    "            req = requests.get(url)\n",
    "            if req.status_code == 200:\n",
    "                content = req.content\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "                post = soup.find(class_='msg').get_text()\n",
    "                resp = soup.find(id=re.compile('bestComment_\\d+')).get_text()\n",
    "\n",
    "                return {'post': post.strip(), 'response': resp.strip()}\n",
    "        \n",
    "        with open(f\"{filename}.csv\", \"a\") as f:\n",
    "            writer = csv.writer(f)\n",
    "        \n",
    "            while len(self.link_list) > 0:\n",
    "                curr_page = self.link_list.pop()\n",
    "\n",
    "                try:\n",
    "                    entry = crawl_single_page(curr_page)\n",
    "                    post, response = entry['post'], entry['response']\n",
    "                    \n",
    "                    if post and len(post) >= 15 and response and len(response) >= 15:\n",
    "                        i = int(curr_page[-9:])\n",
    "                        writer.writerow([i, curr_page, post, response])\n",
    "                        self.n_row += 1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                clear_output(wait=True)\n",
    "                print(f\"Row: {self.n_row}  Remaining: {len(self.link_list)}\")\n",
    "\n",
    "dh = DHCrawler(base_site='https://forum.donanimhaber.com')\n",
    "dh(filename='forum_dh2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f93d7-bc7a-4225-95b2-47d327af887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "def merge_files(*args):\n",
    "    ids = []\n",
    "    \n",
    "    with open(args[-1], \"w\") as out_f:\n",
    "        writer = csv.writer(out_f)\n",
    "        writer.writerow(['id', 'url', 'post', 'response'])\n",
    "        \n",
    "        for arg in args[:-1]:\n",
    "            with open(arg) as in_f:\n",
    "                reader = csv.reader(in_f)\n",
    "                \n",
    "                for row in reader:\n",
    "                    try:\n",
    "                        int(row[0])\n",
    "                        if row[0] not in ids:\n",
    "                            ids.append(row[0])\n",
    "                            writer.writerow(row)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "#merge_files('forum_dh.csv', 'forum_dh1.csv', 'forum_dh2.csv', 'out.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4344d797-1253-4dc4-9b61-703ff84fbfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3188</td>\n",
       "      <td>3188</td>\n",
       "      <td>3188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1699</td>\n",
       "      <td>1774</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Yayıncılığını Electronic Arts'ın yaptığı, oyun...</td>\n",
       "      <td>68F4EBC952C431952F5E4FCDEC52DB7B0CA550AD2D21E5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "count                                                3188   \n",
       "unique                                               1699   \n",
       "top     Yayıncılığını Electronic Arts'ın yaptığı, oyun...   \n",
       "freq                                                    6   \n",
       "\n",
       "                                                 response  label  \n",
       "count                                                3188   3188  \n",
       "unique                                               1774      2  \n",
       "top     68F4EBC952C431952F5E4FCDEC52DB7B0CA550AD2D21E5...      1  \n",
       "freq                                                    9   1598  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "def random_except(a, b, e):\n",
    "    while True:\n",
    "        r = randint(a, b)\n",
    "        if r not in e:\n",
    "            return r\n",
    "\n",
    "def generate_dataset(data_path, frac=0.75, repeat=None):\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    true_pairs = df.sample(frac=frac)[['post', 'response']]\n",
    "    true_pairs = true_pairs.assign(label=[1]*len(true_pairs))\n",
    "\n",
    "    false_responses = df[~df.index.isin(true_pairs.index)]['response']\n",
    "\n",
    "    if repeat is None:\n",
    "        repeat = int(frac / (1-frac))\n",
    "\n",
    "    false_pairs = pd.DataFrame(columns=['post', 'response', 'label'])\n",
    "\n",
    "    for _ in range(repeat):\n",
    "        for i, resp in false_responses.iteritems():\n",
    "            rand_ind = random_except(0, len(df)-1, [i])\n",
    "            post = df.post[rand_ind]\n",
    "            generated_false = pd.DataFrame(data=[{'post': post, 'response': resp, 'label': 0}])\n",
    "\n",
    "            false_pairs = pd.concat([false_pairs, generated_false], ignore_index=True)\n",
    "\n",
    "    all_pairs = pd.concat([true_pairs, false_pairs], ignore_index=True)\n",
    "    all_pairs = all_pairs.drop_duplicates()\n",
    "    \n",
    "    return all_pairs.sample(frac=1)\n",
    "\n",
    "#true_pairs = generate_dataset('forum_dh.csv', frac=1, repeat=0)\n",
    "#false_pairs = generate_dataset('forum_dh.csv', frac=0, repeat=1)\n",
    "\n",
    "#balanced_dataset = pd.concat([true_pairs, false_pairs], ignore_index=True)\n",
    "balanced_dataset = generate_dataset('forum_dh.csv', frac=.9)\n",
    "balanced_dataset.to_parquet('post_resp_dataset_90.parquet')\n",
    "balanced_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14cd4f12-e502-431f-bcc5-545eae94aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188\n",
      "3188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('post_resp_dataset_90.csv')\n",
    "print(len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572390f8-96ee-4e96-bd24-e0fb89517b0e",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e774ee9c-5c61-407e-b3a9-35d139edcd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kia önümüzdeki hafta Detroit Otomobil Fuarı'nd...</td>\n",
       "      <td>iyi görünüyor tabii boşline versiyonunu görmek...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selam dostlar, \"Ghostrunner\" yeni sürüm olduğu...</td>\n",
       "      <td>https://gameolog.net/gundem/ghostrunner-turkce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pekin geçtiğimiz günlerde, Çin İnternet toplul...</td>\n",
       "      <td>Sabit bir şekilde 20-30 hız verseler her kulla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barış Murat YağcıAtakan ArslanAdem KılıçcıBatu...</td>\n",
       "      <td>@Alinda98 @Jankat @mr.yasoo @franz392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyundai ve Kia, elektrikli otomobil sürücüleri...</td>\n",
       "      <td>Pil teknolojilerinde radikal bir gelişim olmad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  \\\n",
       "0  Kia önümüzdeki hafta Detroit Otomobil Fuarı'nd...   \n",
       "1  Selam dostlar, \"Ghostrunner\" yeni sürüm olduğu...   \n",
       "2  Pekin geçtiğimiz günlerde, Çin İnternet toplul...   \n",
       "3  Barış Murat YağcıAtakan ArslanAdem KılıçcıBatu...   \n",
       "4  Hyundai ve Kia, elektrikli otomobil sürücüleri...   \n",
       "\n",
       "                                            response  label  \n",
       "0  iyi görünüyor tabii boşline versiyonunu görmek...      1  \n",
       "1  https://gameolog.net/gundem/ghostrunner-turkce...      1  \n",
       "2  Sabit bir şekilde 20-30 hız verseler her kulla...      1  \n",
       "3              @Alinda98 @Jankat @mr.yasoo @franz392      1  \n",
       "4  Pil teknolojilerinde radikal bir gelişim olmad...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = 'post_response_75_512.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa38625-9918-48a0-add1-7ffa0fc85c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post', 'response', 'label'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f03a22b-cc37-43bc-9808-ea560728738e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fdac23c-15be-461f-a881-a974dc5f5378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post        0\n",
       "response    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e06c75a0-9eb1-4475-8a7f-0364107792fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "      <th>post_length</th>\n",
       "      <th>response_length</th>\n",
       "      <th>content</th>\n",
       "      <th>content_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kia önümüzdeki hafta Detroit Otomobil Fuarı'nd...</td>\n",
       "      <td>iyi görünüyor tabii boşline versiyonunu görmek...</td>\n",
       "      <td>1</td>\n",
       "      <td>239</td>\n",
       "      <td>13</td>\n",
       "      <td>Kia önümüzdeki hafta Detroit Otomobil Fuarı'nd...</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selam dostlar, \"Ghostrunner\" yeni sürüm olduğu...</td>\n",
       "      <td>https://gameolog.net/gundem/ghostrunner-turkce...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Selam dostlar, \"Ghostrunner\" yeni sürüm olduğu...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pekin geçtiğimiz günlerde, Çin İnternet toplul...</td>\n",
       "      <td>Sabit bir şekilde 20-30 hız verseler her kulla...</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>26</td>\n",
       "      <td>Pekin geçtiğimiz günlerde, Çin İnternet toplul...</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barış Murat YağcıAtakan ArslanAdem KılıçcıBatu...</td>\n",
       "      <td>@Alinda98 @Jankat @mr.yasoo @franz392</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>Barış Murat YağcıAtakan ArslanAdem KılıçcıBatu...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyundai ve Kia, elektrikli otomobil sürücüleri...</td>\n",
       "      <td>Pil teknolojilerinde radikal bir gelişim olmad...</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>46</td>\n",
       "      <td>Hyundai ve Kia, elektrikli otomobil sürücüleri...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  \\\n",
       "0  Kia önümüzdeki hafta Detroit Otomobil Fuarı'nd...   \n",
       "1  Selam dostlar, \"Ghostrunner\" yeni sürüm olduğu...   \n",
       "2  Pekin geçtiğimiz günlerde, Çin İnternet toplul...   \n",
       "3  Barış Murat YağcıAtakan ArslanAdem KılıçcıBatu...   \n",
       "4  Hyundai ve Kia, elektrikli otomobil sürücüleri...   \n",
       "\n",
       "                                            response  label  post_length  \\\n",
       "0  iyi görünüyor tabii boşline versiyonunu görmek...      1          239   \n",
       "1  https://gameolog.net/gundem/ghostrunner-turkce...      1           18   \n",
       "2  Sabit bir şekilde 20-30 hız verseler her kulla...      1          171   \n",
       "3              @Alinda98 @Jankat @mr.yasoo @franz392      1           41   \n",
       "4  Pil teknolojilerinde radikal bir gelişim olmad...      1          204   \n",
       "\n",
       "   response_length                                            content  \\\n",
       "0               13  Kia önümüzdeki hafta Detroit Otomobil Fuarı'nd...   \n",
       "1                5  Selam dostlar, \"Ghostrunner\" yeni sürüm olduğu...   \n",
       "2               26  Pekin geçtiğimiz günlerde, Çin İnternet toplul...   \n",
       "3                4  Barış Murat YağcıAtakan ArslanAdem KılıçcıBatu...   \n",
       "4               46  Hyundai ve Kia, elektrikli otomobil sürücüleri...   \n",
       "\n",
       "   content_length  \n",
       "0             252  \n",
       "1              23  \n",
       "2             197  \n",
       "3              45  \n",
       "4             250  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = lambda x: len(x.split())  # or len\n",
    "\n",
    "df['post_length'] = df['post'].apply(func)\n",
    "df['response_length'] = df['response'].apply(func)\n",
    "\n",
    "df['content'] = df['post'] + ' ' + df['response']\n",
    "df['content_length'] = df['content'].apply(func)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d166416d-5a5c-4c2b-b4f5-893a9b368bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>post_length</th>\n",
       "      <th>response_length</th>\n",
       "      <th>content_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.512525</td>\n",
       "      <td>101.842685</td>\n",
       "      <td>29.662325</td>\n",
       "      <td>131.505010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499968</td>\n",
       "      <td>77.113992</td>\n",
       "      <td>36.489326</td>\n",
       "      <td>80.695644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>353.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>356.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label  post_length  response_length  content_length\n",
       "count  1996.000000  1996.000000      1996.000000     1996.000000\n",
       "mean      0.512525   101.842685        29.662325      131.505010\n",
       "std       0.499968    77.113992        36.489326       80.695644\n",
       "min       0.000000     1.000000         2.000000        4.000000\n",
       "25%       0.000000    32.000000         9.000000       59.000000\n",
       "50%       1.000000    88.000000        18.000000      126.000000\n",
       "75%       1.000000   162.000000        33.000000      190.000000\n",
       "max       1.000000   353.000000       326.000000      356.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc72fc2-30c9-4c51-a5a0-83d7a6028665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 44564/44564 [00:00<00:00, 437826.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ᴴᴰ', 44563),\n",
       " ('örtüsünü', 43297),\n",
       " ('önümüzdeki', 43265),\n",
       " ('nda', 30532),\n",
       " ('kaldıracağı', 25835),\n",
       " ('hafta', 23223),\n",
       " ('Otomobil', 7950),\n",
       " ('Fuarı', 4917),\n",
       " ('Detroit', 3954),\n",
       " ('2018', 609)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_most_frequents(col):\n",
    "    vectorizer = CountVectorizer(lowercase=False)\n",
    "    X = vectorizer.fit_transform(df[col])\n",
    "\n",
    "    ls = []\n",
    "    for k, v in tqdm(vectorizer.vocabulary_.items()):\n",
    "        if len(ls) < 10:\n",
    "            ls.append((k, v))\n",
    "        else:\n",
    "            idx = min([i for i, el in enumerate(ls)])\n",
    "            if v > ls[idx][1]:\n",
    "                ls[idx] = (k, v)\n",
    "\n",
    "    ls.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ls\n",
    "\n",
    "find_most_frequents(col='content')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
