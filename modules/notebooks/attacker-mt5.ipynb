{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install evaluate\n",
    "!pip install sacrebleu"
   ],
   "metadata": {
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:41:57.789968Z",
     "iopub.execute_input": "2023-04-12T07:41:57.790777Z",
     "iopub.status.idle": "2023-04-12T07:42:20.600574Z",
     "shell.execute_reply.started": "2023-04-12T07:41:57.790735Z",
     "shell.execute_reply": "2023-04-12T07:42:20.599242Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m81.4/81.4 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2023.1.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.12.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (23.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.11.4)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (5.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.11.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.7.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\n\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0mCollecting sacrebleu\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m118.9/118.9 kB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2021.11.10)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (1.21.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (4.9.2)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.7.0)\nInstalling collected packages: sacrebleu\nSuccessfully installed sacrebleu-2.3.1\n\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, MT5ForConditionalGeneration, set_seed\n",
    "# import evaluate\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "#bleu = evaluate.load('sacrebleu')"
   ],
   "metadata": {
    "id": "w8IHlnyX14Tn",
    "execution": {
     "iopub.status.busy": "2023-04-12T07:42:20.603963Z",
     "iopub.execute_input": "2023-04-12T07:42:20.604355Z",
     "iopub.status.idle": "2023-04-12T07:42:34.685294Z",
     "shell.execute_reply.started": "2023-04-12T07:42:20.604311Z",
     "shell.execute_reply": "2023-04-12T07:42:34.684193Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TData(Dataset):\n",
    "    def __init__(self, df, tokenizer, device='cpu'):\n",
    "        super(TData, self).__init__()\n",
    "\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device= device\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "\n",
    "        cloze = f'answer: {row[\"answer\"]} context: {row[\"cloze\"]}'\n",
    "        question = f'question: {row[\"question\"]}'\n",
    "        \n",
    "        encoder_inputs = self.tokenizer(cloze, padding='max_length', max_length=256,\n",
    "                                        truncation=True, return_tensors='pt')\n",
    "        decoder_outputs = self.tokenizer(question, padding='max_length', max_length=256,\n",
    "                                         truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        encoder_inputs = {k: v[0].to(self.device) for k, v in encoder_inputs.items()}\n",
    "        decoder_outputs = {f'decoder_{k}': v[0].to(self.device) for k, v in decoder_outputs.items()}\n",
    "\n",
    "        return {**encoder_inputs, **decoder_outputs, 'labels': decoder_outputs['decoder_input_ids']}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "szatB93k14To",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:42:34.687154Z",
     "iopub.execute_input": "2023-04-12T07:42:34.687898Z",
     "iopub.status.idle": "2023-04-12T07:42:34.697395Z",
     "shell.execute_reply.started": "2023-04-12T07:42:34.687839Z",
     "shell.execute_reply": "2023-04-12T07:42:34.695802Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_step(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses, ppls, bleus = [], [], []\n",
    "    pbar = tqdm(train_loader)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(**batch)\n",
    "        loss = out.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        ppls.append(math.exp(loss.item()))\n",
    "        \n",
    "        references = [[o] for o in tokenizer.batch_decode(batch['decoder_input_ids'], skip_special_tokens=True)]\n",
    "        predictions = tokenizer.batch_decode(out.logits.argmax(dim=-1), skip_special_tokens=True)\n",
    "        results = bleu.compute(predictions=predictions, references=references)\n",
    "        bleus.append(results['score'])\n",
    "\n",
    "        pbar.set_description(f'Batch {i+1}/{len(train_loader)}: Loss: {np.mean(losses):.4f} - Perplexity: {np.mean(ppls):.4f} - Bleu: {np.mean(bleus):.4f}')\n",
    "\n",
    "    return np.mean(losses), np.mean(ppls), np.mean(bleus)\n",
    "\n",
    "\n",
    "def eval_step(model, val_loader):\n",
    "    model.eval()\n",
    "\n",
    "    losses, ppls, bleus = [], [], []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader)\n",
    "        for i, batch in enumerate(pbar):\n",
    "            out = model(**batch)\n",
    "            loss = out.loss           \n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            ppls.append(math.exp(loss.item()))\n",
    "            \n",
    "            references = [[o] for o in tokenizer.batch_decode(batch['decoder_input_ids'], skip_special_tokens=True)]\n",
    "            predictions = tokenizer.batch_decode(out.logits.argmax(dim=-1), skip_special_tokens=True)\n",
    "            results = bleu.compute(predictions=predictions, references=references)\n",
    "            bleus.append(results['score'])\n",
    "            \n",
    "            pbar.set_description(f'Batch {i+1}/{len(val_loader)}: Loss: {np.mean(losses):.4f} - Perplexity: {np.mean(ppls):.4f} - Bleu: {np.mean(bleus):.4f}')\n",
    "        \n",
    "            if i == 0:\n",
    "                print('Example Reference: ', references[0])\n",
    "                print('Example Prediction: ', predictions[0])\n",
    "\n",
    "    return np.mean(losses), np.mean(ppls), np.mean(bleus)\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, val_loader=None, device='cpu'):\n",
    "    train_losses, train_ppls, train_bleus = [], [], []\n",
    "    val_losses, val_ppls, val_bleus = [], [], []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}')\n",
    "\n",
    "        train_loss, train_ppl, train_bleu = train_step(model, train_loader, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "        train_ppls.append(train_ppl)\n",
    "        train_bleus.append(train_bleu)\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_loss, val_ppl, val_bleu = eval_step(model, val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            val_ppls.append(val_ppl)\n",
    "            val_bleus.append(val_bleu)\n",
    "        \n",
    "        test_case = val_df.iloc[0]\n",
    "        question = ask(model, test_case.answer, test_case.cloze, device=DEVICE)\n",
    "        print(f'GENERATED -> {question}')\n",
    "\n",
    "    return train_losses, train_ppls, train_bleus, val_losses, val_ppls, val_bleus\n",
    "\n",
    "@torch.no_grad()\n",
    "def ask(model, answer, cloze, device='cpu'):\n",
    "    encoder_inputs = tokenizer(f'answer: {answer} context: {cloze}', return_tensors='pt', truncation=True).input_ids.to(device)\n",
    "    decoder_inputs = tokenizer('question: ', return_tensors='pt', add_special_tokens=False).input_ids.to(device)\n",
    "    \n",
    "    \"\"\"\n",
    "    generated_ids = model.generate(encoder_inputs,\n",
    "                                   decoder_input_ids=decoder_inputs,\n",
    "                                   pad_token_id=tokenizer.eos_token_id,\n",
    "                                   num_beams=5, do_sample=True,\n",
    "                                   top_k=50, top_p=0.95, early_stopping=True,\n",
    "                                   no_repeat_ngram_size=1,\n",
    "                                   max_new_tokens=50, num_return_sequences=1)\n",
    "    \"\"\"\n",
    "    generated_ids = model.generate(encoder_inputs, decoder_input_ids=decoder_inputs,\n",
    "                                   num_beams=1, num_return_sequences=1, \n",
    "                                   do_sample=False, max_new_tokens=50)\n",
    "\n",
    "    return tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "ask(model, answer=answer, cloze=cloze, device='cpu')"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "dfeasnWf14Tp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a21c6758-e2cf-479f-e24c-68ce701eb060",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:44:32.787041Z",
     "iopub.execute_input": "2023-04-12T07:44:32.787679Z",
     "iopub.status.idle": "2023-04-12T07:44:32.814697Z",
     "shell.execute_reply.started": "2023-04-12T07:44:32.787629Z",
     "shell.execute_reply": "2023-04-12T07:44:32.813544Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[\"question:'''''''''''''''''''''''''\"]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google/mt5-small')\n",
    "model = MT5ForConditionalGeneration.from_pretrained('google/mt5-small').to('cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "['question:::::::::::::::::::::::::::::::::::::::::::::::::::']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze = '''Panthers hattında ayrıca, sadece 9 başlangıçta 5 sack eden uç çizgi savunmacısı Kony Ealy ile birlikte 136 kez ile NFL'nin aktif kariyer sack lideri ve 5 kez profesyonel bir top atıcısı olan Jared Allen öne çıkmaktadır.'''\n",
    "answer = '''136'''\n",
    "\n",
    "ask(model, answer=answer, cloze=cloze, device='cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'generated_text': '<extra_id_0> lideri'}]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
    "generator(f'answer: {answer} context: {cloze}', max_length=50, num_beams=1, do_sample=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "TRAIN_DIR = '/kaggle/input/my-quad/my_quad.csv'\n",
    "\n",
    "trainval_df = pd.read_csv(TRAIN_DIR)\n",
    "\n",
    "train_df = trainval_df.sample(frac=.85, random_state=42)\n",
    "val_df = trainval_df.drop(train_df.index)"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "oO-VZWdQ14Tq",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:42:34.723476Z",
     "iopub.execute_input": "2023-04-12T07:42:34.723967Z",
     "iopub.status.idle": "2023-04-12T07:42:34.792314Z",
     "shell.execute_reply.started": "2023-04-12T07:42:34.723928Z",
     "shell.execute_reply": "2023-04-12T07:42:34.791329Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 2\n",
    "EPOCHS = 20\n",
    "DEVICE = 'cuda'"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "D5HVYRr414Tq",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:42:34.793972Z",
     "iopub.execute_input": "2023-04-12T07:42:34.794387Z",
     "iopub.status.idle": "2023-04-12T07:42:34.800678Z",
     "shell.execute_reply.started": "2023-04-12T07:42:34.794348Z",
     "shell.execute_reply": "2023-04-12T07:42:34.799580Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_path = 'google/mt5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_path).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adadelta(model.parameters())"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "5iey1hlJ14Tq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "72750b2d-a55e-45e9-d5ca-539a4fba29ed",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:42:34.802484Z",
     "iopub.execute_input": "2023-04-12T07:42:34.803244Z",
     "iopub.status.idle": "2023-04-12T07:43:01.965784Z",
     "shell.execute_reply.started": "2023-04-12T07:42:34.803207Z",
     "shell.execute_reply": "2023-04-12T07:43:01.964732Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "749a1414250c4a4483e7bd35bec483b9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "447c355dc84048878cc9ada055c1c493"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d05e6cc4732428f8c3133451a9bfec4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f35d0889d781439d887e7dbbb8dc860e"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.20G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40bfd5abe62347a98488e9e798ab6dee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f162fdce29114df38771b5fbe8b9d8ad"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = TData(train_df, tokenizer, device=DEVICE)\n",
    "val_data = TData(val_df, tokenizer, device=DEVICE)"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "R9v2Vmpa14Tr",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:43:01.967308Z",
     "iopub.execute_input": "2023-04-12T07:43:01.967666Z",
     "iopub.status.idle": "2023-04-12T07:43:01.972505Z",
     "shell.execute_reply.started": "2023-04-12T07:43:01.967627Z",
     "shell.execute_reply": "2023-04-12T07:43:01.971474Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mTData\u001B[49m(train_df, tokenizer, device\u001B[38;5;241m=\u001B[39mDEVICE)\n\u001B[1;32m      2\u001B[0m val_data \u001B[38;5;241m=\u001B[39m TData(val_df, tokenizer, device\u001B[38;5;241m=\u001B[39mDEVICE)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'TData' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "d29O2WhO14Tr",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:43:01.974018Z",
     "iopub.execute_input": "2023-04-12T07:43:01.974649Z",
     "iopub.status.idle": "2023-04-12T07:43:01.983767Z",
     "shell.execute_reply.started": "2023-04-12T07:43:01.974610Z",
     "shell.execute_reply": "2023-04-12T07:43:01.982828Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ex = val_df.iloc[0]\n",
    "print(f'answer -> {ex.answer}\\ncloze -> {ex.cloze}\\nquestion -> {ex.question}')"
   ],
   "metadata": {
    "id": "9YPsBOEL14Tt",
    "outputId": "daaa5978-1544-4a89-cd53-50ff1187372c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "execution": {
     "iopub.status.busy": "2023-04-12T07:43:01.988115Z",
     "iopub.execute_input": "2023-04-12T07:43:01.988430Z",
     "iopub.status.idle": "2023-04-12T07:43:02.000267Z",
     "shell.execute_reply.started": "2023-04-12T07:43:01.988402Z",
     "shell.execute_reply": "2023-04-12T07:43:01.999236Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "answer -> 136\ncloze ->  Panthers hattında ayrıca, sadece 9 başlangıçta 5 sack eden uç çizgi savunmacısı Kony Ealy ile birlikte 136 kez ile NFL'nin aktif kariyer sack lideri ve 5 kez profesyonel bir top atıcısı olan Jared Allen öne çıkmaktadır.\nquestion -> Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_losses, train_ppls, train_bleus, val_losses, val_ppls, val_bleus = train(model, train_loader, optimizer, val_loader=val_loader, device=DEVICE)"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    },
    "id": "2hgnXJWI14Tt",
    "outputId": "d9aa8ac6-3ce7-40e1-f91f-955ee6ce36d0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2023-04-12T07:45:33.622369Z",
     "iopub.execute_input": "2023-04-12T07:45:33.623162Z",
     "iopub.status.idle": "2023-04-12T08:25:27.951830Z",
     "shell.execute_reply.started": "2023-04-12T07:45:33.623122Z",
     "shell.execute_reply": "2023-04-12T08:25:27.950729Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 1.3193 - Perplexity: 2293294902424658727927808.0000 - Bleu: 3.0374: 100%|██████████| 566/566 [01:54<00:00,  4.93it/s] \nBatch 5/100: Loss: 0.4483 - Perplexity: 1.5682 - Bleu: 6.2415:   3%|▎         | 3/100 [00:00<00:04, 21.41it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: ne  yıli ne ne ne ne    ne?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.4573 - Perplexity: 1.5908 - Bleu: 5.6788: 100%|██████████| 100/100 [00:04<00:00, 20.93it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 2/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.4311 - Perplexity: 1.5515 - Bleu: 6.1357: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.3083 - Perplexity: 1.3638 - Bleu: 8.2176:   3%|▎         | 3/100 [00:00<00:04, 21.42it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: questionadı İ'ın kaç kaç kaçadı ilmiştir adıadı?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.3331 - Perplexity: 1.4016 - Bleu: 8.2496: 100%|██████████| 100/100 [00:05<00:00, 19.67it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 3/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.2577 - Perplexity: 1.3009 - Bleu: 10.3577: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.0507 - Perplexity: 1.0521 - Bleu: 46.1296:   3%|▎         | 3/100 [00:00<00:04, 21.74it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane taneer eden edmektedir vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0710 - Perplexity: 1.0740 - Bleu: 41.5976: 100%|██████████| 100/100 [00:04<00:00, 21.13it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 4/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.1043 - Perplexity: 1.1114 - Bleu: 25.8855: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.0065 - Perplexity: 1.0065 - Bleu: 89.4749:   3%|▎         | 3/100 [00:00<00:04, 20.87it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0154 - Perplexity: 1.0156 - Bleu: 79.8600: 100%|██████████| 100/100 [00:04<00:00, 20.97it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 5/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0534 - Perplexity: 1.0552 - Bleu: 44.6756: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.0028 - Perplexity: 1.0028 - Bleu: 97.6677:   3%|▎         | 3/100 [00:00<00:04, 21.04it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0074 - Perplexity: 1.0074 - Bleu: 90.5437: 100%|██████████| 100/100 [00:04<00:00, 20.97it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 6/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0344 - Perplexity: 1.0352 - Bleu: 57.7159: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.0012 - Perplexity: 1.0012 - Bleu: 97.6677:   3%|▎         | 3/100 [00:00<00:04, 21.51it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0034 - Perplexity: 1.0034 - Bleu: 95.2444: 100%|██████████| 100/100 [00:04<00:00, 20.75it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 7/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0256 - Perplexity: 1.0260 - Bleu: 65.8121: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 5/100: Loss: 0.0005 - Perplexity: 1.0005 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.43it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0029 - Perplexity: 1.0029 - Bleu: 95.4572: 100%|██████████| 100/100 [00:05<00:00, 19.55it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 8/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0191 - Perplexity: 1.0193 - Bleu: 71.7069: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.0003 - Perplexity: 1.0003 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.64it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0023 - Perplexity: 1.0023 - Bleu: 96.6362: 100%|██████████| 100/100 [00:04<00:00, 20.86it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 9/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0159 - Perplexity: 1.0161 - Bleu: 76.2055: 100%|██████████| 566/566 [01:55<00:00,  4.92it/s]\nBatch 5/100: Loss: 0.0003 - Perplexity: 1.0003 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.29it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0017 - Perplexity: 1.0017 - Bleu: 96.9264: 100%|██████████| 100/100 [00:04<00:00, 20.35it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 10/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0135 - Perplexity: 1.0136 - Bleu: 79.7002: 100%|██████████| 566/566 [01:54<00:00,  4.94it/s]\nBatch 5/100: Loss: 0.0002 - Perplexity: 1.0002 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.49it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0018 - Perplexity: 1.0018 - Bleu: 96.8738: 100%|██████████| 100/100 [00:04<00:00, 20.94it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 11/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0111 - Perplexity: 1.0112 - Bleu: 82.0375: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.0001 - Perplexity: 1.0001 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.23it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0014 - Perplexity: 1.0014 - Bleu: 97.0582: 100%|██████████| 100/100 [00:04<00:00, 20.97it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 12/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0095 - Perplexity: 1.0096 - Bleu: 84.6348: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 4/100: Loss: 0.0000 - Perplexity: 1.0000 - Bleu: 100.0000:   4%|▍         | 4/100 [00:00<00:05, 16.09it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0010 - Perplexity: 1.0010 - Bleu: 97.9793: 100%|██████████| 100/100 [00:05<00:00, 19.64it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 13/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0087 - Perplexity: 1.0088 - Bleu: 85.4465: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 5/100: Loss: 0.0002 - Perplexity: 1.0002 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.45it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0013 - Perplexity: 1.0013 - Bleu: 97.2855: 100%|██████████| 100/100 [00:04<00:00, 20.78it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 14/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0074 - Perplexity: 1.0075 - Bleu: 87.3720: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 5/100: Loss: 0.0006 - Perplexity: 1.0006 - Bleu: 98.0823:   3%|▎         | 3/100 [00:00<00:04, 21.33it/s] ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0012 - Perplexity: 1.0013 - Bleu: 97.5209: 100%|██████████| 100/100 [00:04<00:00, 20.60it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 15/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0066 - Perplexity: 1.0066 - Bleu: 88.4932: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 5/100: Loss: 0.0001 - Perplexity: 1.0001 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.72it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0013 - Perplexity: 1.0013 - Bleu: 97.1753: 100%|██████████| 100/100 [00:04<00:00, 21.08it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 16/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0057 - Perplexity: 1.0057 - Bleu: 89.0434: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 5/100: Loss: 0.0002 - Perplexity: 1.0002 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.63it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0010 - Perplexity: 1.0010 - Bleu: 97.4340: 100%|██████████| 100/100 [00:04<00:00, 21.23it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 17/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0052 - Perplexity: 1.0052 - Bleu: 90.7826: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 4/100: Loss: 0.0001 - Perplexity: 1.0001 - Bleu: 100.0000:   2%|▏         | 2/100 [00:00<00:06, 15.59it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0011 - Perplexity: 1.0011 - Bleu: 97.5330: 100%|██████████| 100/100 [00:04<00:00, 20.26it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 18/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0050 - Perplexity: 1.0050 - Bleu: 91.0255: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 4/100: Loss: 0.0000 - Perplexity: 1.0000 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 20.63it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0011 - Perplexity: 1.0011 - Bleu: 97.7591: 100%|██████████| 100/100 [00:04<00:00, 21.19it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 19/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0049 - Perplexity: 1.0049 - Bleu: 91.3461: 100%|██████████| 566/566 [01:54<00:00,  4.96it/s]\nBatch 5/100: Loss: 0.0001 - Perplexity: 1.0001 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.60it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0012 - Perplexity: 1.0012 - Bleu: 97.8853: 100%|██████████| 100/100 [00:04<00:00, 20.91it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\nEpoch 20/20\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 566/566: Loss: 0.0040 - Perplexity: 1.0040 - Bleu: 92.6174: 100%|██████████| 566/566 [01:54<00:00,  4.95it/s]\nBatch 5/100: Loss: 0.0002 - Perplexity: 1.0002 - Bleu: 100.0000:   3%|▎         | 3/100 [00:00<00:04, 21.38it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Example Reference:  [\"question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\"]\nExample Prediction:  question: Jared Allen'ın kaç tane kariyer sack edişi vardır?\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Batch 100/100: Loss: 0.0008 - Perplexity: 1.0008 - Bleu: 98.5489: 100%|██████████| 100/100 [00:04<00:00, 20.93it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GENERATED -> ['question:::::::::::::::::::::::::::::::::::::::::::::::::::']\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ex = val_df.iloc[0]\n",
    "ask(model, ex.answer, ex.cloze, device=DEVICE)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-12T07:44:35.946456Z",
     "iopub.execute_input": "2023-04-12T07:44:35.947076Z",
     "iopub.status.idle": "2023-04-12T07:44:38.235299Z",
     "shell.execute_reply.started": "2023-04-12T07:44:35.947031Z",
     "shell.execute_reply": "2023-04-12T07:44:38.234120Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "execution_count": 17,
     "output_type": "execute_result",
     "data": {
      "text/plain": "[\"question:'''''''''''''''''''''''' '\"]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.save_pretrained('mt5_12april')"
   ],
   "metadata": {
    "id": "oUp2Ioq3zGDt",
    "execution": {
     "iopub.status.busy": "2023-04-12T08:25:27.953844Z",
     "iopub.execute_input": "2023-04-12T08:25:27.954732Z",
     "iopub.status.idle": "2023-04-12T08:25:30.159412Z",
     "shell.execute_reply.started": "2023-04-12T08:25:27.954702Z",
     "shell.execute_reply": "2023-04-12T08:25:30.158368Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r best_bert_gpt2.zip best_bert_gpt2/"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    pass"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "id": "SR9CJTgFOG80",
    "outputId": "9dcebfa4-5799-4d1f-fc05-7a94672e8b6c",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cp /content/attacker_bert_gpt2.pt /content/drive/MyDrive/adversarial-taboo/adversarial-taboo-models"
   ],
   "metadata": {
    "id": "defGD0aSPKS3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "h7BLnxVuQAKO"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
