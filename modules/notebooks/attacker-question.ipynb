{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "! pip install zemberek-python\n! curl https://huggingface.co/datasets/husnu/tquad2/raw/main/tquad_train_data_v2.json > tquad_train_data_v2.json\n! curl https://huggingface.co/datasets/husnu/tquad2/raw/main/tquad_dev_data_v2.json > tquad_dev_data_v2.json",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import math\nimport pandas as pd\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport pytorch_lightning as pl\n\nfrom transformers import MT5ForConditionalGeneration, MT5TokenizerFast\n\nfrom zemberek import TurkishSentenceExtractor\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:56.632257Z",
     "iopub.execute_input": "2023-02-28T06:24:56.632701Z",
     "iopub.status.idle": "2023-02-28T06:24:58.958267Z",
     "shell.execute_reply.started": "2023-02-28T06:24:56.632597Z",
     "shell.execute_reply": "2023-02-28T06:24:58.957261Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def tquad2df(path):\n    extractor = TurkishSentenceExtractor()\n\n    df = {'title': [], 'context': [], 'question': [], 'cloze': [], 'answer': []}\n\n    dataset = pd.read_json(path).data\n\n\n    for data in dataset:\n        title = data['title']\n        for para in data['paragraphs']:\n            context = para['context']\n            for qa in para['qas']:\n                question = qa['question']\n\n                unique_answers = set()\n                for answer in qa['answers']:\n                    answer_text, answer_span = answer['text'], int(answer['answer_start'])\n                    spans = extractor.extract_to_spans(context)\n\n                    for span in spans:\n                        if answer_text not in unique_answers and span.in_span(answer_span):\n                            unique_answers.add(answer_text)\n                            cloze = span.get_sub_string(context)\n                            df['title'].append(title)\n                            df['context'].append(context)\n                            df['question'].append(question)\n                            df['cloze'].append(cloze)\n                            df['answer'].append(answer_text)\n\n    return pd.DataFrame(df)\n",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.959889Z",
     "iopub.execute_input": "2023-02-28T06:24:58.960621Z",
     "iopub.status.idle": "2023-02-28T06:24:58.969876Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.960572Z",
     "shell.execute_reply": "2023-02-28T06:24:58.968904Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def create_text(**kwargs):\n    answer = kwargs['answer']\n    cloze = kwargs['cloze']\n    return f\"generate question for answer {answer} : {cloze}\"",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.971363Z",
     "iopub.execute_input": "2023-02-28T06:24:58.971979Z",
     "iopub.status.idle": "2023-02-28T06:24:58.984078Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.971918Z",
     "shell.execute_reply": "2023-02-28T06:24:58.983223Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class TData(Dataset):\n    def __init__(self, df, tokenizer):\n        super(TData, self).__init__()\n\n        self.df = df\n        self.tok = tokenizer\n\n    def __getitem__(self, i):\n        row = self.df.iloc[i]\n\n        text = create_text(answer=row['answer'], cloze=row['cloze'])\n\n        model_inputs = self.tok(text, padding='max_length', max_length=256,\n                                truncation=True, return_tensors='pt')\n        with self.tok.as_target_tokenizer():\n            labels = self.tok(row['question'], padding='max_length', max_length=256,\n                                truncation=True, return_tensors=\"pt\")\n        model_inputs[\"labels\"] = labels[\"input_ids\"]\n\n        return {k: v[0] for k, v in model_inputs.items()}\n\n    def __len__(self):\n        return len(self.df)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.987206Z",
     "iopub.execute_input": "2023-02-28T06:24:58.987767Z",
     "iopub.status.idle": "2023-02-28T06:24:58.996242Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.987730Z",
     "shell.execute_reply": "2023-02-28T06:24:58.995276Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TRAIN_DIR = '../../taboo-datasets/tquad2/tquad_train_data_v2.json'\n",
    "DEV_DIR= '../../taboo-datasets/tquad2/tquad_dev_data_v2.json'\n",
    "\n",
    "train_df = tquad2df(TRAIN_DIR)\n",
    "val_df = tquad2df(DEV_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.997515Z",
     "iopub.execute_input": "2023-02-28T06:24:58.998037Z",
     "iopub.status.idle": "2023-02-28T06:25:07.916965Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.998002Z",
     "shell.execute_reply": "2023-02-28T06:25:07.916001Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'Kim geldiÄŸinde orijinal viking yerleÅŸimcilerine ortak bir kimlik vermiÅŸtir?'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0].question"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": "model = MT5ForConditionalGeneration.from_pretrained('google/mt5-small', force_download=True)\ntokenizer = MT5TokenizerFast.from_pretrained('google/mt5-small')",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:07.918522Z",
     "iopub.execute_input": "2023-02-28T06:25:07.918930Z",
     "iopub.status.idle": "2023-02-28T06:25:44.953377Z",
     "shell.execute_reply.started": "2023-02-28T06:25:07.918891Z",
     "shell.execute_reply": "2023-02-28T06:25:44.952254Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/553 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4036ad9752ad4756a2bccd3926dcc20d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bfa88ef354849ceb19cbbc28a29957e"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "train_data = TData(train_df, tokenizer)\nval_data = TData(val_df, tokenizer)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.954921Z",
     "iopub.execute_input": "2023-02-28T06:25:44.955408Z",
     "iopub.status.idle": "2023-02-28T06:25:44.960872Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.955370Z",
     "shell.execute_reply": "2023-02-28T06:25:44.959618Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class AttackerModel(pl.LightningModule):\n    def __init__(self, model, lr):\n        super(AttackerModel, self).__init__()\n\n        self.model = model\n        self.lr = lr\n\n    def forward(self, **batch):\n        return self.model(**batch)\n\n    def training_step(self, batch, batch_idx):\n        loss = self(**batch).loss\n        self.log_dict({'loss': loss, 'ppl': math.exp(loss.item())}, \n                      prog_bar=True, on_step=True, on_epoch=True)\n\n        if batch_idx % 500 == 0:\n            with torch.no_grad():\n                sentence = train_df.iloc[0]\n                text = create_text(**sentence)\n                tokenized_sent = tokenizer(text, padding='max_length', max_length=256,\n                                           truncation=True, return_tensors='pt')\n                generated_question = self.model.cuda().generate(tokenized_sent['input_ids'].cuda(), max_length=256, do_sample=True, top_k=50,\n                                                                      top_p=0.95, num_beams=5, num_return_sequences=3)\n                print(tokenizer.batch_decode(generated_question, skip_special_tokens=True))\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss = self(**batch).loss\n        self.log_dict({'loss': loss, 'ppl': math.exp(loss.item())}, \n                      prog_bar=True, on_step=True, on_epoch=True)\n\n    def configure_optimizers(self):\n        return optim.AdamW(self.model.parameters())\n",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.962549Z",
     "iopub.execute_input": "2023-02-28T06:25:44.962973Z",
     "iopub.status.idle": "2023-02-28T06:25:44.976776Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.962917Z",
     "shell.execute_reply": "2023-02-28T06:25:44.975716Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "BATCH_SIZE = 8\nLR = 1e-3\nEPOCHS = 15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.978639Z",
     "iopub.execute_input": "2023-02-28T06:25:44.979409Z",
     "iopub.status.idle": "2023-02-28T06:25:44.991894Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.979370Z",
     "shell.execute_reply": "2023-02-28T06:25:44.990706Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=BATCH_SIZE)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.996527Z",
     "iopub.execute_input": "2023-02-28T06:25:44.996852Z",
     "iopub.status.idle": "2023-02-28T06:25:45.004064Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.996826Z",
     "shell.execute_reply": "2023-02-28T06:25:45.002980Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "attacker_model = AttackerModel(model=model, lr=LR)\ntrainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=EPOCHS)\ntrainer.fit(model=attacker_model, train_dataloaders=train_loader, val_dataloaders=val_loader)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:45.005708Z",
     "iopub.execute_input": "2023-02-28T06:25:45.006644Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "2023-02-28 06:25:45,057 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: GPU available: True (cuda), used: True\n\n2023-02-28 06:25:45,058 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: TPU available: False, using: 0 TPU cores\n\n2023-02-28 06:25:45,059 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: IPU available: False, using: 0 IPUs\n\n2023-02-28 06:25:45,061 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: HPU available: False, using: 0 HPUs\n\n2023-02-28 06:25:46,821 - pytorch_lightning.accelerators.cuda - INFO\nMsg: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n2023-02-28 06:25:46,834 - pytorch_lightning.callbacks.model_summary - INFO\nMsg: \n  | Name  | Type                        | Params\n------------------------------------------------------\n0 | model | MT5ForConditionalGeneration | 300 M \n------------------------------------------------------\n300 M     Trainable params\n0         Non-trainable params\n300 M     Total params\n1,200.707 Total estimated model params size (MB)\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24aa081231e54e53a3c138ab588cf162"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"<extra_id_0> '-a\", '<extra_id_0>igma)==  <extra_id_4>hinja <extra_id_33>Ğ½ÑƒĞºĞ»Ğµ <extra_id_31>â€œ <extra_id_31> vulner <extra_id_31> <extra_id_31>ÑƒĞ»Ğ°Ğ½à¥à¤¬à¤¾Î½Ï„Î±Î½à®•à¯à®•à¯€××•×–Î±ÏƒÎºà·à¶»à·à¶» <extra_id_44>-Ğ²Ğ¾Ğ·Ğ±ÑƒĞ´ <extra_id_33>à¸ªà¸¡à¸²à¸Šà¸´à¸ dispuà·à¶½à¸‚à¹‰à¸­ç¾è¡ŒáƒáƒŸ <extra_id_39>rzejà·’à¶±à·Õ²Õ¢Ğ¿Ğ½Ğµå“” <extra_id_31>áƒœáƒáƒ¬@ <extra_id_34> Altersintari <extra_id_33>', 'saanĞ¾Ä‘Ğ³Ñ€Ğ°Ğ´ĞµğŸ–ã‚ªãƒ³ <extra_id_54>áƒ˜áƒ¢áƒ”áƒ¢ReplyDeleteAddpratsiyon']\n['<extra_id_0>', '<extra_id_0>?', '<extra_id_0>']\n['<extra_id_0> ', 'Ne', '<extra_id_0>']\n[\"' y?? ne   ? ???\", 'Kim   ', '<extra_id_0>.?']\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "['Ib?', 'Ä° II Ä°  a', 'Hang Ä° ???? hangi']\n['Åeh ? hangidir? a?', \"Osman'?\", \"OsmanlaÅŸmasÄ± nerede' hangi  hangi???\"]\n['hangi hangi??', 'hangi hangi Devlet Mustafa hangi?', 'Ä°. hangi hangi?']\n['Kim.Ã¼d nerede? hangi?', 'Kim.? hangi hangi??', 'Mustafa hangi hangi hangi?']\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "['Mahmu hangi hangi hangi??', 'hangi hangidi hangi hangi?', 'hangi?']\n['hangi hangi hangi yÄ±lÄ±nda hangi? s', 'hangi tarihinde hangi?', 'Ä°bn Murad hangi tarihte?']\n['Åehzade Mustafa hangi aittir?', \"I. AbdÃ¼lhan'in adÄ± nedir?\", 'Mustafa hangi arasÄ±nda hangi arasÄ±nda hangi adÄ± nedir?']\n[\"AydÄ±n'da imzalarÄ± arasÄ±nda adÄ± nedir?\", 'II. Selim adÄ± nedir?', \"II. SÃ¼leyman'Ä±n adÄ± nedir?\"]\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"Ä°bn-i. SÃ¼leyman'nÄ±n tahta Ã§Ä±ktÄ±ÄŸÄ±nda nereye gitmiÅŸtir?\", \"Ä°bn-i Batuta'nÄ±n adÄ± nedir?\", 'III. Murad, hangi tarihte hangi Ã¼niversitede Ã¶lmÃ¼ÅŸtÃ¼r?']\n[\"Ä°bn-i Batuta'nÄ±n hangi Ã¼niversiteye baÅŸlamÄ±ÅŸtÄ±r?\", \"Ä°bn-i Batuta'nÄ±n hangi yÄ±lda Ã¶lmÃ¼ÅŸtÃ¼r?\", \"IV. Murad'in adÄ± nedir?\"]\n[\"Ä°bn-i Batuta'nÄ±n adÄ± nedir?\", \"Ä°bn-i Heysem'in adÄ± nedir?\", \"Ä°bn-i Heysem'in babasÄ±nÄ±n adÄ± nedir?\"]\n[\"II. Mustafa Ä°lhamit'in nerede doÄŸmuÅŸtur?\", \"Ä°bn-i Batuta'nÄ±n yanÄ±nda ne zaman vefat etti?\", \"Ä°bn el-Cezeri'nin mesleÄŸi nedir?\"]\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"Ä°bn RÃ¼ÅŸd'in Ã¶lÃ¼m sebebi nedir?\", 'II. Mehmed nerede doÄŸmuÅŸtur?', \"II. Bayezid'in saltanatÄ± kimdir?\"]\n['Hangi antlaÅŸmadÄ±r?', 'Hangi antlaÅŸmaya gÃ¶re hangi antlaÅŸmadÄ±r?', \"Ä°bn-i Batuta'nÄ±n hangi Ã¼lkede yapÄ±ldÄ±?\"]\n[\"I. Mahmud'Ä±n babasÄ± kimdir?\", 'Kimin babasÄ± kimdir?', \"Ä°bn-i Batuta'nÄ±n adÄ± nedir?\"]\n['II. Bayezid hangi tarihte Ã¶lmÃ¼ÅŸtÃ¼r?', \"II. Mustafa'nÄ±n yeÄŸeni Feyzullah Efendi'nin neyi ele geÃ§irmiÅŸtir?\", \"II. Mustafa'nÄ±n babasÄ± kimdir?\"]\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"II. Mehmed'in babasÄ± kimdir?\", \"I. Bayezid'den sonra gelen padiÅŸahÄ±n adÄ± nedir?\", \"I. SÃ¼leyman'Ä±n babasÄ± kimdir?\"]\n['Åehzade Selim nerede doÄŸmuÅŸtur?', \"II. Mehmed'in saltanatÄ± kaÃ§ yÄ±lÄ±nda Ã¶lmÃ¼ÅŸtÃ¼r?\", 'Kim, divan edebiyatÄ±ndaki mahlasÄ± kimdir?']\n[\"Ä°bn TaÄŸrÄ±berdÃ®'nin Ã¶lÃ¼m sebebi nedir?\", \"Aziz Sancar'Ä±n babasÄ± kimdir?\", \"II. Bayezid'in saltanatÄ± kaÃ§ yÄ±lÄ±nda baÅŸlamÄ±ÅŸtÄ±r?\"]\n[\"Ä°bn-i Batuta'nÄ±n yazarÄ± kimdir?\", \"Ä°bn-i Batuta'nÄ±n yazarÄ± kimdir?\", 'AydÄ±n SayÄ±lÄ± hangi bÃ¶lÃ¼mden mezun olmuÅŸtur?']\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"Ä°bn-i Batuta'nÄ±n asÄ±l adÄ± nedir?\", \"Åehzade Bayezid'in babasÄ± kimdir?\", \"AydÄ±n SayÄ±lÄ±'nÄ±n doÄŸum yeri neresidir?\"]\n['II. Bayezid hangi tarihte Ã¶lmÃ¼ÅŸtÃ¼r?', \"II. Bayezid'in ikinci sefer-i kime aittir?\", 'II. Bayezid hangi tarihte Ã¶lmÃ¼ÅŸtÃ¼r?']\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
