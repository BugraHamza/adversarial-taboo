{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "! pip install zemberek-python\n! curl https://huggingface.co/datasets/husnu/tquad2/raw/main/tquad_train_data_v2.json > tquad_train_data_v2.json\n! curl https://huggingface.co/datasets/husnu/tquad2/raw/main/tquad_dev_data_v2.json > tquad_dev_data_v2.json",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import math\nimport pandas as pd\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport pytorch_lightning as pl\n\nfrom transformers import MT5ForConditionalGeneration, MT5TokenizerFast\n\nfrom zemberek import TurkishSentenceExtractor\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:56.632257Z",
     "iopub.execute_input": "2023-02-28T06:24:56.632701Z",
     "iopub.status.idle": "2023-02-28T06:24:58.958267Z",
     "shell.execute_reply.started": "2023-02-28T06:24:56.632597Z",
     "shell.execute_reply": "2023-02-28T06:24:58.957261Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def tquad2df(path):\n    extractor = TurkishSentenceExtractor()\n\n    df = {'title': [], 'context': [], 'question': [], 'cloze': [], 'answer': []}\n\n    dataset = pd.read_json(path).data\n\n\n    for data in dataset:\n        title = data['title']\n        for para in data['paragraphs']:\n            context = para['context']\n            for qa in para['qas']:\n                question = qa['question']\n\n                unique_answers = set()\n                for answer in qa['answers']:\n                    answer_text, answer_span = answer['text'], int(answer['answer_start'])\n                    spans = extractor.extract_to_spans(context)\n\n                    for span in spans:\n                        if answer_text not in unique_answers and span.in_span(answer_span):\n                            unique_answers.add(answer_text)\n                            cloze = span.get_sub_string(context)\n                            df['title'].append(title)\n                            df['context'].append(context)\n                            df['question'].append(question)\n                            df['cloze'].append(cloze)\n                            df['answer'].append(answer_text)\n\n    return pd.DataFrame(df)\n",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.959889Z",
     "iopub.execute_input": "2023-02-28T06:24:58.960621Z",
     "iopub.status.idle": "2023-02-28T06:24:58.969876Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.960572Z",
     "shell.execute_reply": "2023-02-28T06:24:58.968904Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def create_text(**kwargs):\n    answer = kwargs['answer']\n    cloze = kwargs['cloze']\n    return f\"generate question for answer {answer} : {cloze}\"",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.971363Z",
     "iopub.execute_input": "2023-02-28T06:24:58.971979Z",
     "iopub.status.idle": "2023-02-28T06:24:58.984078Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.971918Z",
     "shell.execute_reply": "2023-02-28T06:24:58.983223Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class TData(Dataset):\n    def __init__(self, df, tokenizer):\n        super(TData, self).__init__()\n\n        self.df = df\n        self.tok = tokenizer\n\n    def __getitem__(self, i):\n        row = self.df.iloc[i]\n\n        text = create_text(answer=row['answer'], cloze=row['cloze'])\n\n        model_inputs = self.tok(text, padding='max_length', max_length=256,\n                                truncation=True, return_tensors='pt')\n        with self.tok.as_target_tokenizer():\n            labels = self.tok(row['question'], padding='max_length', max_length=256,\n                                truncation=True, return_tensors=\"pt\")\n        model_inputs[\"labels\"] = labels[\"input_ids\"]\n\n        return {k: v[0] for k, v in model_inputs.items()}\n\n    def __len__(self):\n        return len(self.df)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.987206Z",
     "iopub.execute_input": "2023-02-28T06:24:58.987767Z",
     "iopub.status.idle": "2023-02-28T06:24:58.996242Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.987730Z",
     "shell.execute_reply": "2023-02-28T06:24:58.995276Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TRAIN_DIR = '../../taboo-datasets/tquad2/tquad_train_data_v2.json'\n",
    "DEV_DIR= '../../taboo-datasets/tquad2/tquad_dev_data_v2.json'\n",
    "\n",
    "train_df = tquad2df(TRAIN_DIR)\n",
    "val_df = tquad2df(DEV_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:24:58.997515Z",
     "iopub.execute_input": "2023-02-28T06:24:58.998037Z",
     "iopub.status.idle": "2023-02-28T06:25:07.916965Z",
     "shell.execute_reply.started": "2023-02-28T06:24:58.998002Z",
     "shell.execute_reply": "2023-02-28T06:25:07.916001Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'Kim geldiğinde orijinal viking yerleşimcilerine ortak bir kimlik vermiştir?'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0].question"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": "model = MT5ForConditionalGeneration.from_pretrained('google/mt5-small', force_download=True)\ntokenizer = MT5TokenizerFast.from_pretrained('google/mt5-small')",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:07.918522Z",
     "iopub.execute_input": "2023-02-28T06:25:07.918930Z",
     "iopub.status.idle": "2023-02-28T06:25:44.953377Z",
     "shell.execute_reply.started": "2023-02-28T06:25:07.918891Z",
     "shell.execute_reply": "2023-02-28T06:25:44.952254Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/553 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4036ad9752ad4756a2bccd3926dcc20d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bfa88ef354849ceb19cbbc28a29957e"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "train_data = TData(train_df, tokenizer)\nval_data = TData(val_df, tokenizer)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.954921Z",
     "iopub.execute_input": "2023-02-28T06:25:44.955408Z",
     "iopub.status.idle": "2023-02-28T06:25:44.960872Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.955370Z",
     "shell.execute_reply": "2023-02-28T06:25:44.959618Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class AttackerModel(pl.LightningModule):\n    def __init__(self, model, lr):\n        super(AttackerModel, self).__init__()\n\n        self.model = model\n        self.lr = lr\n\n    def forward(self, **batch):\n        return self.model(**batch)\n\n    def training_step(self, batch, batch_idx):\n        loss = self(**batch).loss\n        self.log_dict({'loss': loss, 'ppl': math.exp(loss.item())}, \n                      prog_bar=True, on_step=True, on_epoch=True)\n\n        if batch_idx % 500 == 0:\n            with torch.no_grad():\n                sentence = train_df.iloc[0]\n                text = create_text(**sentence)\n                tokenized_sent = tokenizer(text, padding='max_length', max_length=256,\n                                           truncation=True, return_tensors='pt')\n                generated_question = self.model.cuda().generate(tokenized_sent['input_ids'].cuda(), max_length=256, do_sample=True, top_k=50,\n                                                                      top_p=0.95, num_beams=5, num_return_sequences=3)\n                print(tokenizer.batch_decode(generated_question, skip_special_tokens=True))\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss = self(**batch).loss\n        self.log_dict({'loss': loss, 'ppl': math.exp(loss.item())}, \n                      prog_bar=True, on_step=True, on_epoch=True)\n\n    def configure_optimizers(self):\n        return optim.AdamW(self.model.parameters())\n",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.962549Z",
     "iopub.execute_input": "2023-02-28T06:25:44.962973Z",
     "iopub.status.idle": "2023-02-28T06:25:44.976776Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.962917Z",
     "shell.execute_reply": "2023-02-28T06:25:44.975716Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "BATCH_SIZE = 8\nLR = 1e-3\nEPOCHS = 15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.978639Z",
     "iopub.execute_input": "2023-02-28T06:25:44.979409Z",
     "iopub.status.idle": "2023-02-28T06:25:44.991894Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.979370Z",
     "shell.execute_reply": "2023-02-28T06:25:44.990706Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=BATCH_SIZE)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:44.996527Z",
     "iopub.execute_input": "2023-02-28T06:25:44.996852Z",
     "iopub.status.idle": "2023-02-28T06:25:45.004064Z",
     "shell.execute_reply.started": "2023-02-28T06:25:44.996826Z",
     "shell.execute_reply": "2023-02-28T06:25:45.002980Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "attacker_model = AttackerModel(model=model, lr=LR)\ntrainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=EPOCHS)\ntrainer.fit(model=attacker_model, train_dataloaders=train_loader, val_dataloaders=val_loader)",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-02-28T06:25:45.005708Z",
     "iopub.execute_input": "2023-02-28T06:25:45.006644Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "2023-02-28 06:25:45,057 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: GPU available: True (cuda), used: True\n\n2023-02-28 06:25:45,058 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: TPU available: False, using: 0 TPU cores\n\n2023-02-28 06:25:45,059 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: IPU available: False, using: 0 IPUs\n\n2023-02-28 06:25:45,061 - pytorch_lightning.utilities.rank_zero - INFO\nMsg: HPU available: False, using: 0 HPUs\n\n2023-02-28 06:25:46,821 - pytorch_lightning.accelerators.cuda - INFO\nMsg: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n2023-02-28 06:25:46,834 - pytorch_lightning.callbacks.model_summary - INFO\nMsg: \n  | Name  | Type                        | Params\n------------------------------------------------------\n0 | model | MT5ForConditionalGeneration | 300 M \n------------------------------------------------------\n300 M     Trainable params\n0         Non-trainable params\n300 M     Total params\n1,200.707 Total estimated model params size (MB)\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24aa081231e54e53a3c138ab588cf162"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"<extra_id_0> '-a\", '<extra_id_0>igma)==  <extra_id_4>hinja <extra_id_33>нукле <extra_id_31>“ <extra_id_31> vulner <extra_id_31> <extra_id_31>улан्बाντανக்கீאוזασκෝරෝර <extra_id_44>-возбуд <extra_id_33>สมาชิก dispuෝලข้อ現行აჟ <extra_id_39>rzejිනාղբпне哔 <extra_id_31>ნაწ@ <extra_id_34> Altersintari <extra_id_33>', 'saanоđграде🖏オン <extra_id_54>იტეტReplyDeleteAddpratsiyon']\n['<extra_id_0>', '<extra_id_0>?', '<extra_id_0>']\n['<extra_id_0> ', 'Ne', '<extra_id_0>']\n[\"' y?? ne   ? ???\", 'Kim   ', '<extra_id_0>.?']\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "['Ib?', 'İ II İ  a', 'Hang İ ???? hangi']\n['Şeh ? hangidir? a?', \"Osman'?\", \"Osmanlaşması nerede' hangi  hangi???\"]\n['hangi hangi??', 'hangi hangi Devlet Mustafa hangi?', 'İ. hangi hangi?']\n['Kim.üd nerede? hangi?', 'Kim.? hangi hangi??', 'Mustafa hangi hangi hangi?']\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "['Mahmu hangi hangi hangi??', 'hangi hangidi hangi hangi?', 'hangi?']\n['hangi hangi hangi yılında hangi? s', 'hangi tarihinde hangi?', 'İbn Murad hangi tarihte?']\n['Şehzade Mustafa hangi aittir?', \"I. Abdülhan'in adı nedir?\", 'Mustafa hangi arasında hangi arasında hangi adı nedir?']\n[\"Aydın'da imzaları arasında adı nedir?\", 'II. Selim adı nedir?', \"II. Süleyman'ın adı nedir?\"]\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"İbn-i. Süleyman'nın tahta çıktığında nereye gitmiştir?\", \"İbn-i Batuta'nın adı nedir?\", 'III. Murad, hangi tarihte hangi üniversitede ölmüştür?']\n[\"İbn-i Batuta'nın hangi üniversiteye başlamıştır?\", \"İbn-i Batuta'nın hangi yılda ölmüştür?\", \"IV. Murad'in adı nedir?\"]\n[\"İbn-i Batuta'nın adı nedir?\", \"İbn-i Heysem'in adı nedir?\", \"İbn-i Heysem'in babasının adı nedir?\"]\n[\"II. Mustafa İlhamit'in nerede doğmuştur?\", \"İbn-i Batuta'nın yanında ne zaman vefat etti?\", \"İbn el-Cezeri'nin mesleği nedir?\"]\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"İbn Rüşd'in ölüm sebebi nedir?\", 'II. Mehmed nerede doğmuştur?', \"II. Bayezid'in saltanatı kimdir?\"]\n['Hangi antlaşmadır?', 'Hangi antlaşmaya göre hangi antlaşmadır?', \"İbn-i Batuta'nın hangi ülkede yapıldı?\"]\n[\"I. Mahmud'ın babası kimdir?\", 'Kimin babası kimdir?', \"İbn-i Batuta'nın adı nedir?\"]\n['II. Bayezid hangi tarihte ölmüştür?', \"II. Mustafa'nın yeğeni Feyzullah Efendi'nin neyi ele geçirmiştir?\", \"II. Mustafa'nın babası kimdir?\"]\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"II. Mehmed'in babası kimdir?\", \"I. Bayezid'den sonra gelen padişahın adı nedir?\", \"I. Süleyman'ın babası kimdir?\"]\n['Şehzade Selim nerede doğmuştur?', \"II. Mehmed'in saltanatı kaç yılında ölmüştür?\", 'Kim, divan edebiyatındaki mahlası kimdir?']\n[\"İbn Tağrıberdî'nin ölüm sebebi nedir?\", \"Aziz Sancar'ın babası kimdir?\", \"II. Bayezid'in saltanatı kaç yılında başlamıştır?\"]\n[\"İbn-i Batuta'nın yazarı kimdir?\", \"İbn-i Batuta'nın yazarı kimdir?\", 'Aydın Sayılı hangi bölümden mezun olmuştur?']\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": ""
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "[\"İbn-i Batuta'nın asıl adı nedir?\", \"Şehzade Bayezid'in babası kimdir?\", \"Aydın Sayılı'nın doğum yeri neresidir?\"]\n['II. Bayezid hangi tarihte ölmüştür?', \"II. Bayezid'in ikinci sefer-i kime aittir?\", 'II. Bayezid hangi tarihte ölmüştür?']\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
