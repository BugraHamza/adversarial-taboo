{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T12:31:15.020075Z",
     "iopub.status.busy": "2022-03-06T12:31:15.019747Z",
     "iopub.status.idle": "2022-03-06T12:31:17.690439Z",
     "shell.execute_reply": "2022-03-06T12:31:17.689711Z",
     "shell.execute_reply.started": "2022-03-06T12:31:15.019996Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T12:31:18.613239Z",
     "iopub.status.busy": "2022-03-06T12:31:18.612495Z",
     "iopub.status.idle": "2022-03-06T12:31:18.620488Z",
     "shell.execute_reply": "2022-03-06T12:31:18.619427Z",
     "shell.execute_reply.started": "2022-03-06T12:31:18.613202Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, device='cpu'):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        post, resp = X[i]        \n",
    "        el_sent = ' '.join([post, self.tokenizer.special_tokens_map['sep_token'], resp])\n",
    "        tokenized_el = self.tokenizer(el_sent, padding='max_length', return_tensors='pt')\n",
    "        \n",
    "        for k, v in tokenized_el.items():\n",
    "            v_device = v.to(self.device)               \n",
    "            tokenized_el[k] = v_device.squeeze()\n",
    "        \n",
    "        return tokenized_el, self.y[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T12:31:19.239451Z",
     "iopub.status.busy": "2022-03-06T12:31:19.239211Z",
     "iopub.status.idle": "2022-03-06T12:31:19.245541Z",
     "shell.execute_reply": "2022-03-06T12:31:19.244777Z",
     "shell.execute_reply.started": "2022-03-06T12:31:19.239424Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifyBERTurk(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ClassifyBERTurk, self).__init__()\n",
    "        self.berturk = AutoModel.from_config(config)\n",
    "        self.fc = nn.Linear(config.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, **inputs):\n",
    "        bert_out = self.berturk(**inputs)\n",
    "        bert_last_hidden = bert_out[0][:, 0, :]\n",
    "        \n",
    "        fc_out = self.fc(bert_last_hidden)\n",
    "        sigmoid_out = self.sigmoid(fc_out)\n",
    "        return sigmoid_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T12:31:19.737161Z",
     "iopub.status.busy": "2022-03-06T12:31:19.736541Z",
     "iopub.status.idle": "2022-03-06T12:31:19.748976Z",
     "shell.execute_reply": "2022-03-06T12:31:19.748272Z",
     "shell.execute_reply.started": "2022-03-06T12:31:19.737130Z"
    }
   },
   "outputs": [],
   "source": [
    "def fine_tune(model, dataloader, epochs, loss_fn, optimizer, \n",
    "              val_dataloader=None, threshold=.4, device='cpu'):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for param in model.berturk.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    num_true, total_count = 0, 0\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(dataloader)\n",
    "        pbar.set_description(f\"Epoch #{epoch+1}\")\n",
    "        for i, batch in enumerate(pbar):\n",
    "            X, y = batch\n",
    "            y = y.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(**X).squeeze()\n",
    "                       \n",
    "            loss = loss_fn(outputs, y)        \n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "               \n",
    "            pred = (outputs > threshold).float()\n",
    "            num_true += sum(pred == y)\n",
    "            total_count += len(y)\n",
    "            acc = num_true / total_count\n",
    "            \n",
    "            pbar.set_postfix(acc=f\"{100*acc:.2f}\", bce_loss=f\"{sum(losses)/len(losses)}\")\n",
    "\n",
    "        if val_dataloader:\n",
    "            test(model, val_dataloader, threshold, device)\n",
    "            \n",
    "    return model, losses\n",
    "\n",
    "\n",
    "def test(model, dataloader, threshold=.4, device='cpu'):\n",
    "    true_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in tqdm(dataloader):\n",
    "            y = y.to(device)\n",
    "            outputs = model(**X).squeeze()\n",
    "            \n",
    "            pred = (outputs > threshold).float()\n",
    "            true_count += sum(pred == y)\n",
    "            total_count += len(y)\n",
    "    acc = true_count/total_count\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T12:31:20.356020Z",
     "iopub.status.busy": "2022-03-06T12:31:20.355763Z",
     "iopub.status.idle": "2022-03-06T12:31:20.361849Z",
     "shell.execute_reply": "2022-03-06T12:31:20.361103Z",
     "shell.execute_reply.started": "2022-03-06T12:31:20.355990Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tokenizable(df, tokenizer):\n",
    "    ls = []\n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        el_sent = ' '.join([row.post, tokenizer.special_tokens_map['sep_token'], row.response])\n",
    "\n",
    "        tok_sent = tokenizer.tokenize(el_sent)\n",
    "        \n",
    "        if len(tok_sent) < tokenizer.model_max_length-1:\n",
    "            ls.append(i)\n",
    "            \n",
    "    return df.iloc[ls, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T12:31:29.615942Z",
     "iopub.status.busy": "2022-03-06T12:31:29.615351Z",
     "iopub.status.idle": "2022-03-06T13:42:43.087370Z",
     "shell.execute_reply": "2022-03-06T13:42:43.085860Z",
     "shell.execute_reply.started": "2022-03-06T12:31:29.615903Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'dbmdz/bert-base-turkish-cased'\n",
    "BATCH_SIZE = 256\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "THRESHOLD = 0.4\n",
    "EPOCHS = 10\n",
    "LR = 0.01\n",
    "\n",
    "last_acc=0\n",
    "while True:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, force_download=True)\n",
    "\n",
    "    df = pd.read_csv('../input/taboo-datasets/post_resp_dataset_75.csv')\n",
    "    df = get_tokenizable(df, tokenizer)\n",
    "\n",
    "    y = df['label'].to_numpy()\n",
    "    X = df.drop('label', axis=1).to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    train_set = CustomDataset(X=X_train, y=y_train, tokenizer=tokenizer, device=DEVICE)\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    test_set = CustomDataset(X=X_test, y=y_test, tokenizer=tokenizer, device=DEVICE)\n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    bert_config = AutoConfig.from_pretrained(MODEL_PATH, force_download=True)\n",
    "    bert_model = ClassifyBERTurk(config=bert_config)\n",
    "    #bert_model = torch.load(MODEL_PATH)\n",
    "\n",
    "    bce_loss = nn.BCELoss()\n",
    "    opt = optim.Adam(bert_model.parameters(), lr=LR)\n",
    "\n",
    "    bert_model, losses = fine_tune(bert_model, train_loader, EPOCHS, loss_fn=bce_loss, \n",
    "                                   optimizer=opt, threshold=THRESHOLD, device=DEVICE)\n",
    "\n",
    "    acc = test(bert_model, test_loader, threshold=THRESHOLD, device=DEVICE)\n",
    "    print(f\"Accuracy: {100*acc:.2f}\")\n",
    "\n",
    "    if acc > last_acc:\n",
    "        torch.save(bert_model, f'adequacy_model_{acc}')\n",
    "        last_acc = acc\n",
    "        \n",
    "    if acc >= 0.55:\n",
    "        torch.save(bert_model, f'adequacy_model_best')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-03-06T11:57:03.444592Z",
     "iopub.status.busy": "2022-03-06T11:57:03.441547Z",
     "iopub.status.idle": "2022-03-06T11:57:03.756359Z",
     "shell.execute_reply": "2022-03-06T11:57:03.755383Z",
     "shell.execute_reply.started": "2022-03-06T11:57:03.444539Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T11:51:03.726668Z",
     "iopub.status.busy": "2022-03-06T11:51:03.726378Z",
     "iopub.status.idle": "2022-03-06T11:51:04.454850Z",
     "shell.execute_reply": "2022-03-06T11:51:04.453823Z",
     "shell.execute_reply.started": "2022-03-06T11:51:03.726635Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(bert_model, f'adequacy_model_{datetime.now():%Y%m%d%H%M%S}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
